{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b78c99-932e-42c9-9727-c855ed3a6663",
   "metadata": {},
   "source": [
    "Практика 3: Задание аналогично заданию 2, но для представления документов используются вектора, которые показывают распределение тем коллекции в этом документе. По сути каждый признак - это тема, значение признака  в векторе - вероятность этой темы в этом документа. Для того. чтобы это сделать используем LDA. + Нужно посмотреть какие темы будут появлятся, что эти темы из себя представляют. Подсказка в файле"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e08261-3087-42b0-a603-235d0bd8c2db",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1e1a1a-5105-4d47-aecd-a619ceb4ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2be0dd-c911-4c85-ba58-cca82245a686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igorkopylov/PycharmProjects/liner_model/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import LdaModel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce4829d-637d-4fb3-8a5c-d5b530e7b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a8a8e8-3d6b-473a-913c-136ad8c6dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего элементов: 2245\n",
      "ко-во элементов из класса 0: 480\n",
      "ко-во элементов из класса 1: 584\n",
      "ко-во элементов из класса 2: 591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "number_of_topic = 3\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "indices = np.where((newsgroups_train.target >= 0) & (newsgroups_train.target <= number_of_topic))[0]\n",
    "texts = [newsgroups_train.data[i] for i in indices]\n",
    "target = np.array([newsgroups_train.target[i] for i in indices])\n",
    "print(f\"Всего элементов: {target.shape[0]}\")\n",
    "for i in range(number_of_topic):\n",
    "    count = np.count_nonzero(target == i)\n",
    "    print(f\"ко-во элементов из класса {i}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8df13b-5906-4f5f-946c-1f0fbdf87657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "\n",
    "def preprocess_text(text): \n",
    "    # Удаление пунктуации\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    lemmatized_tokens = lemmatize_tokens(tokens)\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22abf83a-6e4b-4e7a-9e55-89ab79961407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From', 'jgreenamber', 'Joe', 'Green', 'Subject']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [preprocess_text(i) for i in texts]\n",
    "tokenized_corpus[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6abc7-7098-4537-919d-663d4cbb2a9c",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33aca4b-d9d4-4a4a-af34-18108c64acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_repo(tokenized_corpus, num_topics=15):\n",
    "    # Создание словаря\n",
    "    dictionary = Dictionary(tokenized_corpus)\n",
    "    \n",
    "    # Преобразование текстов в мешок слов\n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in tokenized_corpus]\n",
    "    \n",
    "    # Обучение модели LDA\n",
    "    lda_model = LdaModel(\n",
    "        corpus=bow_corpus,  # Мешок слов\n",
    "        id2word=dictionary,  # Словарь\n",
    "        num_topics=num_topics,  # Количество тем\n",
    "        passes=10,  # Количество итераций по корпусу\n",
    "        iterations=100,  # Количество итераций для оценки параметров\n",
    "        random_state=42  # Зафиксированный случайный seed для воспроизводимости результатов\n",
    "    )\n",
    "    return lda_model, bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f07e33-2fec-42e1-86cb-72ce001e955b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae1aac478ea441bbd9ae572b0b7e693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=6)  \n",
    "maxi_f1 = -1\n",
    "count_of_sample = 100\n",
    "best_param = []\n",
    "for num_top in tqdm(range(1800, 2000, 10)):\n",
    "    lda_model, bow_corpus = lda_repo(tokenized_corpus[:count_of_sample], num_top)\n",
    "    lda_vec = []\n",
    "    # получаем тематические векторы\n",
    "    for i in range(count_of_sample):\n",
    "        doc_topics = lda_model.get_document_topics(bow_corpus[i])\n",
    "        doc_vec = np.zeros(num_top)\n",
    "        for topic, prob in doc_topics:\n",
    "            #top_numb = int(re.sub(r'[a-zA-Z]', '', topic))\n",
    "            doc_vec[topic] = prob\n",
    "        if len(doc_vec) != num_top:\n",
    "            raise \"jopa\"\n",
    "        lda_vec.append(doc_vec)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(lda_vec, target[:count_of_sample], test_size=0.2, random_state=42)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    if f1 > maxi_f1:\n",
    "        maxi_f1 = f1\n",
    "        best_param = num_top\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61fbf814-5983-460b-bbcf-bd6f20f886f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad067ce-8ec0-4847-a008-e61b1a56d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, bow_corpus = lda_repo(tokenized_corpus, best_param)\n",
    "lda_vec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d6ef7da-00ae-4536-b039-94b936b92db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cadfdc2cfd47dcbfd11bf2377741d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# получаем тематические векторы\n",
    "for i in tqdm(range(len(target))):\n",
    "    doc_topics = lda_model.get_document_topics(bow_corpus[i])\n",
    "    doc_vec = np.zeros(best_param)\n",
    "    for topic, prob in doc_topics:\n",
    "        #top_numb = int(re.sub(r'[a-zA-Z]', '', topic))\n",
    "        doc_vec[topic] = prob\n",
    "    lda_vec.append(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28873b74-df65-4a39-af1b-ad35cf1f1ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2245 1810 2245\n"
     ]
    }
   ],
   "source": [
    "print(len(lda_vec), len(lda_vec[0]), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "473499b1-53f2-4ccf-8912-e027cd8dd552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема 1053: 0.000*\"mail\" + 0.000*\"file\" + 0.000*\"image\" + 0.000*\"3D\" + 0.000*\"send\" + 0.000*\"ray\" + 0.000*\"The\" + 0.000*\"object\" + 0.000*\"format\" + 0.000*\"also\"\n",
      "Тема 782: 0.260*\"VLB\" + 0.120*\"actually\" + 0.095*\"Have\" + 0.094*\"happens\" + 0.064*\"hook\" + 0.057*\"seen\" + 0.046*\"ever\" + 0.038*\"slows\" + 0.037*\"bus\" + 0.031*\"killed\"\n",
      "Тема 91: 0.000*\"algebraically\" + 0.000*\"afil\" + 0.000*\"interection\" + 0.000*\"colinier\" + 0.000*\"colinear\" + 0.000*\"saturncsswinozau\" + 0.000*\"alansaturncsswinOZAU\" + 0.000*\"Repeat\" + 0.000*\"Swinburne\" + 0.000*\"7th\"\n",
      "Тема 1387: 0.000*\"algebraically\" + 0.000*\"afil\" + 0.000*\"interection\" + 0.000*\"colinier\" + 0.000*\"colinear\" + 0.000*\"saturncsswinozau\" + 0.000*\"alansaturncsswinOZAU\" + 0.000*\"Repeat\" + 0.000*\"Swinburne\" + 0.000*\"7th\"\n",
      "Тема 1247: 0.000*\"algebraically\" + 0.000*\"afil\" + 0.000*\"interection\" + 0.000*\"colinier\" + 0.000*\"colinear\" + 0.000*\"saturncsswinozau\" + 0.000*\"alansaturncsswinOZAU\" + 0.000*\"Repeat\" + 0.000*\"Swinburne\" + 0.000*\"7th\"\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic_words in lda_model.show_topics()[:5]:\n",
    "    print(f\"Тема {topic_id}: {topic_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278a1ad-4581-48b7-95ac-f570055a3723",
   "metadata": {},
   "source": [
    "# Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2ccc463-395f-46b9-9433-59bc0e1bba7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая глубина дерева 89\n",
      "значение F1-score:0.6106153023551465\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lda_vec, target, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'max_depth': range(30, 100, 1)}\n",
    "\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Лучшая глубина дерева {grid_search.best_params_['max_depth']}\")\n",
    "print(f\"значение F1-score:{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ec3d4-a32d-471c-8df5-3efbe37846dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
